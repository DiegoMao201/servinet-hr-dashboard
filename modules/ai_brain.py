import streamlit as st
import openai
import json
import os

# Configuraci칩n de la API Key
# Prioridad: 1. Coolify (Env Var) -> 2. Local (secrets.toml)
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key and "openai" in st.secrets:
    api_key = st.secrets["openai"]["api_key"]

# Inicializamos el cliente si hay llave
if api_key:
    client = openai.OpenAI(api_key=api_key)
else:
    client = None

def generate_role_profile(cargo, company_context):
    """
    Crea el Manual de Funciones personalizado.
    Modelo: gpt-4o-mini (Econ칩mico y R치pido)
    """
    if not client: return "丘멆잺 Error: Falta configurar OPENAI_API_KEY."

    prompt = f"""
    Act칰a como un Director de RRHH experto en normas ISO.
    
    CONTEXTO DE LA EMPRESA (Manuales):
    {company_context[:20000]} 
    
    TAREA:
    Genera un perfil de cargo profesional para: "{cargo}".
    
    El formato debe ser HTML limpio (sin ```html ni markdown) para mostrar en web.
    Usa iconos y un dise침o corporativo moderno (Azul/Gris).
    
    SECCIONES OBLIGATORIAS:
    1. 游꿢 Objetivo del Cargo (Estrat칠gico).
    2. 游닆 Funciones Principales (Lista con vi침etas).
    3. 游댃 Procesos Clave (D칤a a d칤a).
    4. 游눠 Habilidades Blandas Requeridas.
    5. 游늵 KPIs Sugeridos.
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # <--- AQU칈 EST츼 EL AHORRO
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        # Limpieza b치sica por si la IA pone bloques de c칩digo
        content = response.choices[0].message.content
        return content.replace("```html", "").replace("```", "")
    except Exception as e:
        return f"Error generando perfil: {e}"

def generate_evaluation(cargo, company_context):
    """
    Crea la evaluaci칩n de desempe침o en formato JSON.
    Modelo: gpt-4o-mini
    """
    if not client: return {}

    prompt = f"""
    Eres experto en psicometr칤a. Basado en los manuales de Servinet, crea una evaluaci칩n para: "{cargo}".
    
    SALIDA: Un JSON v치lido con esta estructura exacta:
    {{
        "preguntas_tecnicas": ["pregunta situacional 1", "pregunta 2", "pregunta 3"],
        "preguntas_blandas": ["pregunta 1", "pregunta 2"],
        "kpis_a_medir": ["kpi 1", "kpi 2"]
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", # <--- MODELO ECON칍MICO
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"Error generando evaluaci칩n: {e}")
        return {"preguntas_tecnicas": ["Error generando preguntas"], "preguntas_blandas": []}

def analyze_results(respuestas_json):
    """
    Analiza las respuestas del empleado.
    Modelo: gpt-4o-mini
    """
    if not client: return "Error de configuraci칩n."

    prompt = f"""
    Analiza estos resultados de evaluaci칩n de desempe침o de un empleado de Servinet:
    {respuestas_json}
    
    Genera un reporte ejecutivo en formato Markdown que incluya:
    1. 游끥 Nivel de competencia (0-100%).
    2. 游 Estado emocional y nivel de estr칠s percibido.
    3. 游꿉 Plan de Capacitaci칩n (3 temas urgentes y pr치cticos).
    4. 丘멆잺 Alerta de Retenci칩n (Riesgo de renuncia? Bajo/Medio/Alto).
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", # <--- MODELO ECON칍MICO
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error analizando resultados: {e}"
